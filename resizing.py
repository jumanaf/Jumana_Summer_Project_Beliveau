# from nd2reader import ND2Reader# import numpy as np# #printing metadata of the images# #with ND2Reader('adamts5_60x_2x2(2).nd2') as images:# #   print(images.metadata)        # #with ND2Reader('adamts5_40x(2).nd2') as images:# #    print(images.metadata)    ##### APPROACH 1# import cv2# from matplotlib import pyplot as plt # # Open the image files. # img1_color = cv2.imread("adamts5_60x_2x2(2)-2.tif") # Image to be aligned. # img2_color = cv2.imread("adamts5_40x(2).tif") # Reference image. # # Convert to grayscale. # #img1 = cv2.cvtColor(img1_color, cv2.COLOR_RGB2GRAY) # #img2 = cv2.cvtColor(img2_color, cv2.COLOR_RGB2GRAY) # #plt.imshow(img1, cmap="gray", vmin=0, vmax=255)# def corners(img_color):#     img = cv2.cvtColor(img_color, cv2.COLOR_RGB2GRAY) #     corners = cv2.goodFeaturesToTrack(img, 25,0.01,10)#     corners = np.int0(corners)#     for i in corners:#         x1,y1 = i.ravel()#         cv2.circle(img,(x1,y1),3,255,-1)#         plt.imshow(img),plt.show()#     keypoints = np.argwhere(corners > 0.01 * corners.max())#     keypoints = [cv2.KeyPoint(float(x[1]), float(x[0]), 13.0) for x in keypoints]#     cv2.KeyPoint_convert(keypoints)#     sift = cv2.xfeatures2d.SIFT_create()#     desc = [sift.compute(img,[kp])[1] for kp in keypoints]    #     return (keypoints, desc)# key1, desc1 = corners(img1_color)# key2, desc2 = corners(img2_color)# desc1 = np.float32(desc1)# desc2 = np.float32(desc2)##### APPROACH 2 FROM https://docs.opencv.org/master/d1/de0/tutorial_py_feature_homography.html with some tweaks, tested on non-cell images#right now, this is being tested on image1 and image2, two images randomly selected from google as test imagesimport numpy as npimport cv2 as cvfrom matplotlib import pyplot as pltMIN_MATCH_COUNT = 10img1 = cv.imread('image_1.png',0)          # queryImageimg2 = cv.imread('image_2.png',0) # trainImageplt.imshow(img1, 'gray'),plt.show()plt.imshow(img2, 'gray'),plt.show()# Initiate SIFT detectorsift = cv.SIFT_create()# find the keypoints and descriptors with SIFTkp1, des1 = sift.detectAndCompute(img1,None)kp2, des2 = sift.detectAndCompute(img2,None)FLANN_INDEX_KDTREE = 1index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)search_params = dict(checks = 50)flann = cv.FlannBasedMatcher(index_params, search_params)matches = flann.knnMatch(des1,des2,k=2)good = []for m,n in matches:    if m.distance < 0.7*n.distance:        good.append(m)if len(good)>MIN_MATCH_COUNT:    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)            matchesMask = mask.ravel().tolist()    h,w = img1.shape    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)    dst = cv.perspectiveTransform(pts,M)    img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)else:    print( "Not enough matches are found - {}/{}".format(len(good), MIN_MATCH_COUNT) )    matchesMask = Nonedraw_params = dict(matchColor = (0,255,0), # draw matches in green color                    singlePointColor = None,                    matchesMask = matchesMask, # draw only inliers                    flags = 2)img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)plt.imshow(img3, 'gray'),plt.show()#this is the part I'm struggling with! Running into small issues with w and h#transformed_img = cv.warpPerspective(img1, M, (w, h)) #plt.imshow(transformed_img, 'gray'),plt.show()# Save the output. #cv.imwrite('output.tif', transformed_img) 